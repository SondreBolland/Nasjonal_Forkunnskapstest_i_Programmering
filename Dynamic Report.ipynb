{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# National Prior Knowledge Test in Programming\n",
    "**Author**: [Sondre Sæther Bolland](https://www.uib.no/personer/Sondre.S%C3%A6ther.Bolland)\n",
    "\n",
    "**Institution**: Department of Informatics, University of Bergen\n",
    "\n",
    "**Email**: sondre.bolland@uib.no"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "The National Prior Knowledge Test in Programming is a tool for assessing students’ programming skill. The test covers the fundamental elements of introductory programming taught at different universities and university colleges in Norway.  The goal of the test is to evaluate students’ level of knowledge regarding the curriculum taught at higher education institutions, regardless of what they have learned in secondary school. By testing the students in the concepts found in CS1 we aim for instructors to be better able to develop and adapt their courses to this new found prior knowledge. The test primarily emphasizes programming taught in mathematics curriculum, as it is the most prevalent source of programming knowledge.\n",
    "\n",
    "This Notebook is a dynamic report of the results from 2023. The (static) written report can be found here: https://programmeringstesten.no/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import PercentFormatter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "Before using this notebook two python scripts need to be run. A requirement to run these scripts is to have the csv file with the original dataset: `total.csv`. This must be placed in the `data` folder in the main directory (where this Notebook is located).\n",
    "\n",
    "`clean_data.py` cleans certain columns for amigious data.\n",
    "\n",
    "`grade_submissions.py` replaces all responses with the number of points they recieved based on the rubric (`rubric.json`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replace escape characters: dict_items([('&lt;', '<'), ('&gt;', '>'), ('&#61;', '='), ('&#34;', '\"'), ('&#43;', '+')])\n",
      "Replace all ambigious institutions with standardized labels: ['UiB', 'NTNU', 'UiS', 'HvL', 'UiO', 'Kristiania', 'NMBU']\n",
      "Replace all ambigious genders with standardized labels: ['m', 'f'] (other gender identities are not included)\n",
      "Rename columns with simpler titles. Easier to use in analysis.\n",
      "Removed all institutions that are not in: ['UiB', 'NTNU', 'UiS', 'HvL', 'UiO', 'Kristiania', 'NMBU']\n",
      "Removed all genders that are not in: ['m', 'f']. The other gender identities do not have a large enough sample size for valid statistical analysis.\n",
      "Removed false entries\n",
      "Removed blank submissions: 57\n"
     ]
    }
   ],
   "source": [
    "!python clean_data.py\n",
    "!python grade_submissions.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graded dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path of the data file\n",
    "path = \"data/\"\n",
    "filename = path + \"results.csv\"\n",
    "df = pd.read_csv(filename, on_bad_lines=\"skip\", delimiter=\";\", encoding=\"utf8\")\n",
    "\n",
    "# Remove all students who have taken a university level course\n",
    "df = df[(df['UniversityExperience'] == 'Nei')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non graded dataset\n",
    "This dataset is used when looking at what the students answered for each task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path of the data file\n",
    "path = \"data/\"\n",
    "filename = path + \"clean.csv\"\n",
    "df_tasks = pd.read_csv(filename, on_bad_lines=\"skip\", delimiter=\";\", encoding=\"utf8\")\n",
    "\n",
    "# Remove all students who have taken a university level course\n",
    "df_tasks = df_tasks[(df_tasks['UniversityExperience'] == 'Nei')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter the dataframe\n",
    "Do you want to look at a specific subset of students?\n",
    "Use the next cell to filter the students based on your criteria.\n",
    "\n",
    "To reset the dataframe, simply run the cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by institution\n",
    "specific_institutions = ['UiO'] # 'UiB', 'NTNU', 'UiS', 'HvL', 'UiO', 'Kristiania', 'NMBU', ' '\n",
    "#df = df[(df['Institution'].isin(specific_institutions))]\n",
    "#df_tasks = df_tasks[(df_tasks['Institution'].isin(specific_institutions))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by Graduate Year\n",
    "specific_graduateyears = ['Før 2020', '2020', '2021 - 2022', '2023'] # 'Før 2020', '2020', '2021 - 2022', '2023'\n",
    "#df = df[(df['GraduateYear'].isin(specific_graduateyears))]\n",
    "#df_tasks = df_tasks[(df_tasks['GraduateYear'].isin(specific_graduateyears))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by Gender\n",
    "specific_genders = ['f', 'm', ' '] # 'f', 'm', ' '\n",
    "#df = df[(df['Gender'].isin(specific_genders))]\n",
    "#df_tasks = df_tasks[(df_tasks['Gender'].isin(specific_genders))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demographics\n",
    "See the background of the students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of students\n",
    "print(f\"The dataset has {len(df['Total'])} student submissions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Institutions\n",
    "Note that there are a large number of submissions that are blank. This is due to the students submitting ambigious answers, which have not been labled by `clean_data.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "institutions = df.Institution.unique()\n",
    "\n",
    "institution_column = \"Institution\"\n",
    "print(df[institution_column].value_counts())\n",
    "df[institution_column].value_counts().plot.pie()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graduate Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = df.GraduateYear.unique()\n",
    "\n",
    "graduateyear_column = \"GraduateYear\"\n",
    "print(df[graduateyear_column].value_counts())\n",
    "df[graduateyear_column].value_counts().plot.pie()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genders = df.Gender.unique()\n",
    "gender_column = \"Gender\"\n",
    "\n",
    "print(df[gender_column].value_counts())\n",
    "print(df[gender_column].value_counts(normalize=True))\n",
    "df[gender_column].value_counts().plot.pie()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Educational Background\n",
    "What courses have these students taken?\n",
    "\n",
    "### Elective Programming Courses\n",
    "During the secondary school phase, students have the option to take three elective courses in programming: *Information Technology 1* (IT1), *Information Technology 2* (IT2), and *Programming and Modelling X* (PMX). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make new column for NO elective programming course\n",
    "courses = ['Informasjonsteknologi 1 (IT1)', 'Informasjonsteknologi 2 (IT2)', 'Programmering og modellering X']\n",
    "df_temp = df[(~df['IT1'].isin(courses))]\n",
    "df_temp = df_temp[(~df_temp['IT2'].isin(courses))]\n",
    "df_temp = df_temp[(~df_temp['PMX'].isin(courses))]\n",
    "df_temp['NoElective'] = ~df_temp['IT1'].isin(courses)\n",
    "\n",
    "df['NoElective'] = df_temp['NoElective']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "courses = ['IT1', 'IT2', 'PMX', 'No Electives']\n",
    "n_it1 = df['IT1'].value_counts()['Informasjonsteknologi 1 (IT1)']\n",
    "n_it2 = df['IT2'].value_counts()['Informasjonsteknologi 2 (IT2)']\n",
    "n_pmx = df['PMX'].value_counts()['Programmering og modellering X']\n",
    "n_noelectives = df['NoElective'].value_counts()[True]\n",
    "counts = [n_it1, n_it2, n_pmx, n_noelectives]\n",
    "\n",
    "ax.bar(courses, counts)\n",
    "ax.set_ylabel('Students')\n",
    "ax.set_title('Courses')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Math Courses\n",
    "The most common math courses available in secondary school are:\n",
    " * Practical Math 1 (1P)\n",
    " * Practical Math 2 (2P)\n",
    " * Theoretical Math 1 (1T)\n",
    " * Social Science Math 1 (S1)\n",
    " * Social Science Math 2 (S2)\n",
    " * Natural Science Math 1 (R1)\n",
    " * Natural Science Math 2 (R2)\n",
    "\n",
    "The majority of students who took the test belonged to STEM fields, where the typical admission requirement includes S1 and S2 or R1 mathematics. Certain math-intensive study programs may also demand R2 mathematics. Notably, most students had completed the Natural Science Math courses (see plot below), which is the most advanced option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "courses = ['P1', 'P2', '1T', 'S1', 'S2', 'R1', 'R2']\n",
    "n_p1 = df['P1'].value_counts()['1P']\n",
    "n_p2 = df['P2'].value_counts()['2P']\n",
    "n_1t = df['T1'].value_counts()['1T']\n",
    "n_s1 = df['S1'].value_counts()['S1']\n",
    "n_s2 = df['S2'].value_counts()['S2']\n",
    "n_r1 = df['R1'].value_counts()['R1']\n",
    "n_r2 = df['R2'].value_counts()['R2']\n",
    "counts = [n_p1, n_p2, n_1t, n_s1, n_s2, n_r1, n_r2]\n",
    "\n",
    "ax.bar(courses, counts)\n",
    "ax.set_ylabel('Students')\n",
    "ax.set_title('Courses')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experience outside of school\n",
    "A source of programming knowledge is self-directed learning outside of formal education, where individuals independently explore the field, using resources like books and online materials. The following plot shows the distribution of students who have at least 30 hours of outside experience with either block based or text based programming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outside_column = \"OutsideExperience\"\n",
    "\n",
    "print(df[outside_column].value_counts())\n",
    "print(df[outside_column].value_counts(normalize=True))\n",
    "df[outside_column].value_counts().plot.pie()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "In this section of the report, the main results are presented before a review of the background the students have on the various study paths and what connection there is between background and results. We also take a close look at how well they performed in specific programming tasks to understand their grasp of the different concepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurations\n",
    "bins = 23\n",
    "edgecolor = 'red'\n",
    "alpha = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Result\n",
    "A histogram of the total score of the students. Maximum score: 22.6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['Total']\n",
    "\n",
    "mean = df.loc[:, 'Total'].mean()\n",
    "sd = df.loc[:, 'Total'].std()\n",
    "print(f'Mean: {round(mean, 3)}')\n",
    "print(f'Standard deviation: {round(sd, 3)}')\n",
    "\n",
    "\n",
    "plt.hist(x, edgecolor=edgecolor, bins=bins)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_distributions(x, y, x_label, y_label):\n",
    "    mean = x.mean()\n",
    "    sd = x.std()\n",
    "    print(f'Mean of {x_label}: {round(mean, 3)}')\n",
    "    print(f'Standard deviation of {x_label}: {round(sd, 3)}')\n",
    "    print()\n",
    "    \n",
    "    mean = y.mean()\n",
    "    sd = y.std()\n",
    "    print(f'Mean of {y_label}: {round(mean, 3)}')\n",
    "    print(f'Standard deviation of {y_label}: {round(sd, 3)}')\n",
    "    \n",
    "    plt.hist(x, bins=bins, alpha=alpha, edgecolor=edgecolor, label=x_label, weights=np.ones(len(x)) / len(x))\n",
    "    plt.hist(y, bins=bins, alpha=alpha, edgecolor=edgecolor, label=y_label, weights=np.ones(len(y)) / len(y))\n",
    "    plt.gca().yaxis.set_major_formatter(PercentFormatter(1))\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prior Programming Experience in Secondary School\n",
    "In the initial segment of the test, we inquired with the students regarding their prior exposure to\n",
    "programming before to commencing their higher education studies.\n",
    "\n",
    "### Graduation Year\n",
    "The educational reforms outlined in LK20 were introduced in the year 2020, resulting in programming becoming a compulsory component solely for those students who graduated in 2023 and onward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[(df['GraduateYear'] == '2023')]['Total']\n",
    "y = df[(df['GraduateYear'].isin(['Før 2020', '2020', '2021 - 2022']))]['Total']\n",
    "\n",
    "x_label = '2023'\n",
    "y_label = 'before 2023'\n",
    "\n",
    "compare_distributions(x, y, x_label, y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots()\n",
    "\n",
    "axes.violinplot(dataset = [df[df.GraduateYear == 'Før 2020'][\"Total\"].values,\n",
    "                           df[df.GraduateYear == '2020'][\"Total\"].values,\n",
    "                           df[df.GraduateYear == '2021 - 2022'][\"Total\"].values,\n",
    "                           df[df.GraduateYear == '2023'][\"Total\"].values],\n",
    "                           \n",
    "                           showmeans=True)\n",
    "\n",
    "axes.set_title('Graduate Year')\n",
    "axes.yaxis.grid(True)\n",
    "axes.set_xlabel('Year')\n",
    "axes.set_ylabel('Total Score')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[(df['Gender'] == 'f')]['Total']\n",
    "y = df[(df['Gender'] == 'm')]['Total']\n",
    "\n",
    "x_label = 'women'\n",
    "y_label = 'men'\n",
    "\n",
    "compare_distributions(x, y, x_label, y_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare two groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select which student groups you want to compare\n",
    "x = df[(df['Institution'] == 'UiB')]['Total']\n",
    "y = df[(df['Institution'] == 'UiO')]['Total']\n",
    "\n",
    "# Change lables as desired\n",
    "x_label = 'UiB'\n",
    "y_label = 'UiO'\n",
    "\n",
    "compare_distributions(x, y, x_label, y_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Tasks\n",
    "Every task featured in the test pertained to a designated concept category. The follwing cells show the number of correct answers and the most common answers for each task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correctness rate for each concept category\n",
    "Below you can find the percentage of accurate responses achieved by the students for each concept.\n",
    "\n",
    "Note that performance within each category may not exclusively reflect the students’ mastery of that programming concept. Variability in task difficulty plays a substantial role, with some tasks naturally being easier than others, irrespective of the underlying concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correctnes_rate(columns, category, task_weight=1):\n",
    "    correct_answer_rate = 0\n",
    "    for column in columns:\n",
    "        task_mean = df.loc[:, column].mean()\n",
    "        correct_answer_rate += task_mean\n",
    "    correct_answer_rate /= len(columns)*task_weight\n",
    "    print(f'{category:15s} {correct_answer_rate*100:3.2f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Booleans\n",
    "boolean_columns = [\"100 == 100\", \"42 != 25\", \"not (100 == 100)\", \"(10*2) > 9\", \"100 >= 100\", \"99 >= 100\", \"100 != (50*2)\", \"(14/2) > 7 \", \"(5 < 7) and (4 > 5)\", \"(3 < 7) and (7 < 9)\", \"(5 < 7) or (4 > 5)\", \"and 500 == 100\", \"(False != False) == (True != True)\", \"(not True) or False\", \"False (not False)\", \"True and False\", \"True and (False or True)\"]\n",
    "correctnes_rate(boolean_columns, \"Booleans\", task_weight=0.2)\n",
    "\n",
    "# Variables\n",
    "variable_columns = [\"Variables1\", \"Variables2\"]\n",
    "correctnes_rate(variable_columns, \"Variables\")\n",
    "\n",
    "# Conditionals\n",
    "conditional_columns = [\"Conditionals1\", \"Conditionals2\", \"Conditionals3\"]\n",
    "correctnes_rate(conditional_columns, \"Conditionals\")\n",
    "\n",
    "# Loops\n",
    "loop_columns = [\"Loops1\", \"Loops2\"]\n",
    "correctnes_rate(loop_columns, \"Loops\")\n",
    "\n",
    "# Lists\n",
    "list_columns = [\"Lists1\", \"Lists2\", \"Lists3\"]\n",
    "correctnes_rate(list_columns, \"Lists\")\n",
    "\n",
    "# Functions\n",
    "function_columns = [\"Functions1\", \"Functions2\", \"Functions3\", \"Functions4\", \"Functions5\", \"Functions6\"]\n",
    "correctnes_rate(function_columns, \"Functions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "To gain a deeper understanding of the students’ knowledge and comprehension of specific programming concepts, it is important to analyze their performance on these concepts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_task_result(task_column, df_results, df_tasks, n_answers=5, verbose_correct_answers=True):\n",
    "    '''\n",
    "    Print number of correct (1) and incorrect (0) responses.\n",
    "    Print the top 5 most common answers.\n",
    "    '''\n",
    "    if verbose_correct_answers:\n",
    "        print(\"Number of correct responses:\")\n",
    "        print(df_results[task_column].value_counts())\n",
    "        print()\n",
    "    \n",
    "    print(f\"Top {n_answers} most common answers:\")\n",
    "    print(df_tasks[task_column].value_counts()[:n_answers])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Booleans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Booleans 1\n",
    "What do these boolean expressions evaluate to?\n",
    "\n",
    "<img src=\"images/Booleans1.png\" alt=\"drawing\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_task_result(\"100 == 100\", df, df_tasks, 3, False)\n",
    "print()\n",
    "print_task_result(\"42 != 25\", df, df_tasks, 3, False)\n",
    "print()\n",
    "print_task_result(\"not (100 == 100)\", df, df_tasks, 3, False)\n",
    "print()\n",
    "print_task_result(\"(10*2) > 9\", df, df_tasks, 3, False)\n",
    "print()\n",
    "print_task_result(\"100 >= 100\", df, df_tasks, 3, False)\n",
    "print()\n",
    "print_task_result(\"99 >= 100\", df, df_tasks, 3, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Booleans 2\n",
    "What do these boolean expressions evaluate to?\n",
    "\n",
    "<img src=\"images/Booleans2.png\" alt=\"drawing\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_task_result(\"100 != (50*2)\", df, df_tasks, 3, False)\n",
    "print()\n",
    "print_task_result(\"(14/2) > 7 \", df, df_tasks, 3, False)\n",
    "print()\n",
    "print_task_result(\"(5 < 7) and (4 > 5)\", df, df_tasks, 3, False)\n",
    "print()\n",
    "print_task_result(\"(3 < 7) and (7 < 9)\", df, df_tasks, 3, False)\n",
    "print()\n",
    "print_task_result(\"(5 < 7) or (4 > 5)\", df, df_tasks, 3, False)\n",
    "print()\n",
    "print_task_result(\"and 500 == 100\", df, df_tasks, 3, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Booleans 3\n",
    "What do these boolean expressions evaluate to?\n",
    "\n",
    "<img src=\"images/Booleans3.png\" alt=\"drawing\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_task_result(\"(False != False) == (True != True)\", df, df_tasks, 3, False)\n",
    "print()\n",
    "print_task_result(\"(not True) or False\", df, df_tasks, 3, False)\n",
    "print()\n",
    "print_task_result(\"False (not False)\", df, df_tasks, 3, False)\n",
    "print()\n",
    "print_task_result(\"True and False\", df, df_tasks, 3, False)\n",
    "print()\n",
    "print_task_result(\"True and (False or True)\", df, df_tasks, 3, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables 1\n",
    "What does this code snippet print?\n",
    "\n",
    "![Variables1](images/Variables1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_task_result(\"Variables1\", df, df_tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables 2\n",
    "\n",
    "What does this code snippet print?\n",
    "\n",
    "<img src=\"images/Variables2.png\" alt=\"drawing\" width=\"200\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_task_result(\"Variables2\", df, df_tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditionals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditionals 1\n",
    "\n",
    "What does this code snippet print?\n",
    "\n",
    "<img src=\"images/Conditionals1.png\" alt=\"drawing\" width=\"200\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_task_result(\"Conditionals1\", df, df_tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditionals 2\n",
    "\n",
    "What must be placed at the red line such that 15 is printed?\n",
    "\n",
    "<img src=\"images/Conditionals2.png\" alt=\"drawing\" width=\"200\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_task_result(\"Conditionals2\", df, df_tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditionals 3\n",
    "\n",
    "What does this code snippet print?\n",
    "\n",
    "<img src=\"images/Conditionals3.png\" alt=\"drawing\" width=\"200\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_task_result(\"Conditionals3\", df, df_tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loops 1\n",
    "\n",
    "What does this code snippet print?\n",
    "\n",
    "<img src=\"images/Loops1.png\" alt=\"drawing\" width=\"200\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_task_result(\"Loops1\", df, df_tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loops 2\n",
    "\n",
    "What does this code snippet print?\n",
    "\n",
    "<img src=\"images/Loops2.png\" alt=\"drawing\" width=\"200\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_task_result(\"Loops2\", df, df_tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lists 1\n",
    "\n",
    "What does this code snippet print?\n",
    "\n",
    "<img src=\"images/Lists1.png\" alt=\"drawing\" width=\"200\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_task_result(\"Lists1\", df, df_tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lists 2\n",
    "\n",
    "What does this code snippet print?\n",
    "\n",
    "<img src=\"images/Lists2.png\" alt=\"drawing\" width=\"200\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_task_result(\"Lists2\", df, df_tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lists 3\n",
    "\n",
    "What does this code snippet print?\n",
    "\n",
    "<img src=\"images/Lists3.png\" alt=\"drawing\" width=\"200\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_task_result(\"Lists3\", df, df_tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions 1\n",
    "\n",
    "What does this code snippet print?\n",
    "\n",
    "<img src=\"images/Functions1.png\" alt=\"drawing\" width=\"200\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_task_result(\"Functions1\", df, df_tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions 2\n",
    "\n",
    "What does this code snippet print?\n",
    "\n",
    "<img src=\"images/Functions2.png\" alt=\"drawing\" width=\"200\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_task_result(\"Functions2\", df, df_tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions 3\n",
    "\n",
    "What code must be written on line 5 so that the function returns the smallest number of the given list?\n",
    "\n",
    "<img src=\"images/Functions3.png\" alt=\"drawing\" width=\"200\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_task_result(\"Functions3\", df, df_tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions 4\n",
    "\n",
    "What does this code snippet print?\n",
    "\n",
    "<img src=\"images/Functions4.png\" alt=\"drawing\" width=\"200\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_task_result(\"Functions4\", df, df_tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions 5\n",
    "\n",
    "What does this code snippet print?\n",
    "\n",
    "<img src=\"images/Functions5.png\" alt=\"drawing\" width=\"200\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_task_result(\"Functions5\", df, df_tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions 6\n",
    "\n",
    "What does this code snippet print?\n",
    "\n",
    "<img src=\"images/Functions6.png\" alt=\"drawing\" width=\"200\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_task_result(\"Functions6\", df, df_tasks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
